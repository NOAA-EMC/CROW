TO DO LIST

For python scripting and python configuration.

------------------------------------------------------------------------
ACTUAL WORKFLOW IN YAML

Modify examples/workflow to generate the actual Rocoto XML for the gfs
workflow, rather than a fake system.

1. The dependencies need to be updated.
2. The resource requirements need to be updated.
3. The shell commands need to be replaced with the actual job script names.

------------------------------------------------------------------------
REPLACE FV3GFS WORKFLOW

- Replace the config.* files with wrappers around the YAML system.

- Update the jobs to use the to_sh.py to get the relevant variables.

- Replace fv3gfs/ush/setup*py with new scripts that are wrapped around
  YAML files.

- Find a way to embed the CROW repository within the fv3gfs repository
  OR create a modulefile and install tags of CROW in a standard area.

Prerequisites:
  ACTUAL WORKFLOW IN YAML
  WORKFLOW ON CRAY
  DELAYED VALIDATION (or suitable workaround in setup*py scripts)

------------------------------------------------------------------------
EVANT/DATA DEPENDENCIES IN WORKFLOW SUITE

The GFS workflow has two types of event dependencies:

1. The post job for hour X must wait to start until the forecast data
is available for hour X.  

2. The prep must wait for observations.  These observations come from
outside the workflow.

In Rocoto, such problems are dealt with via data dependencies.  This
would require placing disk location awareness at the workflow suite
level.  The ecFlow approach is to use events.  This allows a clean
separation between the workflow and dataflow.  In Rocoto, events can
be implemented via flag files.  Either way, we need a dataflow system
or a temporary kludge to replace one.

A solution must be implemented soon (~1 week) to support real-time
parallels and running the post in parallel with the forecast.

------------------------------------------------------------------------
GENERATION OF MPI/OPENMP LAUNCHERS

This is ~50% done.  Sam can probably finish the Theia implementation
in a day or so.

The scripts need to be able to generate mpirun/srun/whatever commands.
For most MPI implementations, this is not as simple as generating one
command.  You will also need files to be generated first, such as
command files or task geometry specifications.  Also, you frequently
need some environment variables.  To accomplish this, we need a type
that passes around the list of files to create (command files, etc.)
the environment, and the command to run.  The YAML needs to have a way
to manually specify that.  Something like this:

launch_me: !ShellCommand
  env:
    LSB_PJL_TASK_GEOMETRY: "{(1,2,3,4)(5,6,7,8)}"
    ANOTHER_VAR: another_value
  files:
    CMD_FILE: 'contents of the command file'
  command: 'mpirun.lsf ... some arguments ...'

From within Python, you need:

1. A ShellCommand object in the config module along with the logic to
read and write it.

2. The scheduler and metascheduler packages need to know how to
generate a ShellCommand.

3. The sysenv package needs to know how to run one.  (This is the
easiest part - probably <10 lines.)

3. There needs to be a shell-side wrapper (like to_sh.py) that knows
how to run the shell command.  It would use the config package ot get
the shell command and the sysenv package to run the command.  This is
easy to implement, and would probably be best done within to_sh.py to
avoid duplicating code.  If it is done that way, it will probably be
<10 lines of added code.

------------------------------------------------------------------------
WORKFLOW ON CRAY

Extend the mpi/openmp launcher work to the WCOSS Cray.  Extend the
Rocoto generation to WCOSS Cray.

Prerequisite: GENERATION OF MPI/OPENMP LAUNCHERS

------------------------------------------------------------------------
SET LAZY EVALUATION (set_eval)

Lists, dicts, and most other types use lazy evaluation for embedded
calculations.  Sets calculate at parse time, which is bad for a number
of reasons.  This needs to be fixed.  The fix is to add a set_eval
class in eval_tools that stores the pre-calculation data in an
internal list (in self.__child) and generates the actual set (in
self.__cache) only when it is needed.  The set_eval would need to be
immutable, unless it invalidates the cache after any change to the
set.



------------------------------------------------------------------------
DELAYED VALIDATION

when a mapping (dict_eval) validates itself via a !Template, any
calculation referred to by the !Template is done during validation.
That means, for example, if you want a date calculation to be done
inside the batch job, that calculation would need to be ommitted
entirely from the YAML that is sent to the setup_expt script.  In
order to avoid that, we need to add a way to delay the validation of
such variables until runtime.  There are two ways I can think of to
handle that:

1. Have a two-stage validation process.  The first stage, run just
after parsing, does not validate anything that requires a calculation.
The second stage can be requested by explicitly running some function,
like crow.config.validate(dict_eval)

2. Allow the YAML to customize the validation for each mapping
somehow.  For example, you could update the validation code so that a
"null" value for a key in the template means the variable should not
be validated.  This would be more error-prone, but it is trivial to
implement.

  fcst:
    fix_path: !calc ENV["FIX_PATH"]
    crtm_fix_path: !expand {fix_path}/crtm-{crtm_version}
    Template:
      <<: *fcst_vars
      # Do not validate crtm_fix_path
      crtm_fix_path: null



------------------------------------------------------------------------
NAMELIST GENERATION

Presently, you can easily do string expansion via !expand:

  block:
    a: 5
    b: 6
    my_text: !expand |
      a is {a}
      b is {b}

That will produce:

a is 5
b is 6

but it is not so easy to generate namelists because the default string
representation of everything is the Python representation.  I added a
tools.fort() function to generate a fortran namelist syntax, but it
makes the text long:

  block:
    list1: [ 5, 6, 7 ]
    list2: [ a, b, c ]
    my_namelist: !expand|
      &my_namelist
        list1: {tools.fort(list1)}
        list2: {tools.fort(list2)}
      /

That will produce:

&my_namelist
  list1: 5, 6, 7
  list2: 'a', 'b', 'c'

I see a few ways of resolving this:

Option 1:

Generate from YAML code.  This is the easiest way, and
is reasonably powerful.  If the user needs something more
sophisticated, they can use !expand or !calc to generate a fancy
namelist.

  block:
    my_namelist: !Namelist
      list1: [ 5, 6, 7 ]
      list2: [ a, b, c ]

Note that we cannot refer to list1 and list2 at the block level from
within my_namelist because my_namelist is in a different scope.  This
reduces the power of the feature.  

Option 2:

The issue in Option 1 can be resolved by using an omap and having the
!Namelist evaluate all expressions in the context of the parent scope.
This would be non-trivial to implement, but feasible.

  block:
    list1: [ 5, 6, 7 ]
    list2: [ a, b, c ]
    my_namelist: !Namelist
      # Note: the calculations refer to the parent scope; the 
      # block-level list1 and list2.
      - list1: !calc list1
      - list2: !calc list2

However, that means that the namelist will be evaluated in the scope
in which it was originally declared.  That is not a terminal problem
because the YAML can always copy the namelist instead of pointing to
it, if it is needed more than once.  

Option 3:

Implicitly add tools.fort() around everything in a {}

  block:
    list1: [ 5, 6, 7 ]
    list2: [ a, b, c ]
    my_namelist: !to_namelist |
      list1 = {list1}
      list2 = {list2}

There are a few problems with that:

1. This is very hard to implement.  It will require complicated
manipulation of the text within the my_namelist.  The {} contents are
Python expressions.  Python expressions cannot be parsed with a single
regular expression (re) because they contain balanced, nested,
parenthesis.  (It is provably impossible to parse nested parentheses
with a regular expression.)  Alternatively, you could write a custom
parser of the string, which would be easier to implement but less
powerful.

2. There is no standard fortran way of expressing datetimes or
timedeltas.  Hence, they will be impossible to express directly in a
!to_namelist block.

3. The user cannot specify numeric or date formatting information
because the result of tools.fort() is already converted to a string.




------------------------------------------------------------------------

TASK ARRAYS (TaskArray)

Add the capability of having an array of nearly-identical tasks in a
suite.

      enkf: !TaskArray
        Index: imem
        Values: !calc tools.seq(1,80) ]
        Name: !expand mem{imem:03d}
        emem: !Task
          Perform: *gdasenkf
          Rocoto: *my_enkf_template
          Trigger: !anal

That would expand out to 80 "emem" tasks with imem set to a number
from 1 to 80 for each one.  

One way to implement this is:

1. TaskArrayYAML in from_yaml.py, TaskArray in tasks.py and
to_yaml.py, associated reading/converting logic.

2. When a SuiteView sees a TaskArray, it needs to automatically
replace it with a Family with one Family for each imem.

3. During the replacement process (#2), the Task, Family, and
TaskArray objects underneath must be duplicated, with "imem" set in
each one.  This must be a shallow copy, so we don't duplicate the
vast YAML object tree.

4. As in #3, all direct children of a Task, Family, and TaskArray must
be copied (shallow) and imem set in each copy.

That is computationally expensive and will use up lots of memory if
there is a large number of tasks.

There may be some more clever way to implement this while avoiding
duplicating anything.  I suspect a TaskArrayView subclass of SuiteView
may be able to do it, if it is implemented in a clever way.  I don't
know what that clever way is though.
