action_template: &action_template
  <<: *resource_defaults
  Template: *fv3_resolution
  BASE_NEMSfv3gfs: !calc doc.case.BASE_NEMSfv3gfs
  CASE: !calc doc.case.CASE
  BASE_GSI: !calc doc.case.BASE_GSI
  BASE_GSM: !calc doc.case.BASE_GSM
  shell_vars: [ "[A-Z][A-Z0-9_]*$", "nth.*", "npe.*" ]
  resource_env: {} # overridden by actions as needed
  accounting: !calc doc.platform.parallel_accounting

ecen: &ecen_action !Action
  <<: *action_template

  # ----------------------------------------
  # From config.resources
  walltime: !timedelta 00:30:00 # was "walltime", renamed to align with 
  resources: !calc run_ecen.resources
  chgres_resources: !calc run_chgres.resources
  resource_env: !calc run_ecen.env
  memory: "3072M" # previously "rocoto_memory", renamed to align with current script

  # Each command (APRUN_whatever) in config.resources needs a
  # run_whatever entry in the corresponding action.
  # Executable name is specified deep inside scripts
  # Use "placeholder" for exe name
  # ----------------------------------------
  # From config.ecen
  ENKFRECENSH: !expand "{doc.case.BASE_GSI}/scripts/EnKF/scripts_ncep/exglobal_enkf_recenter_fv3gfs.sh.ecf"
  nth_ecen: !calc doc.platform.nodes.omp_threads_for(resources[0])
  APRUN_CHGRES: "time"
  APRUN_ECEN: "'mpirun -np 84'"
  ATARDIR: "/NCEPDEV/emc-global/1year/Samuel.Trahan/THEIA/scratch/wham"
  BASE_ENV: !expand "{doc.case.HOMEgfs}/gfs_workflow.v15.0.0/env"
  BASE_JOB: !expand "{doc.case.BASE_WORKFLOW}/jobs"
  CHGRESSH: !expand "{doc.case.BASE_GSM}/ush/global_chgres_GSM.sh"
  CHGRESEXEC: !expand "{doc.case.BASE_GSM}/exec/global_chgres_GSM"
  CHGRESVARS_ENKF: "use_ufo=.true.,nopdpvv=.true."
  CHGRESTHREAD: !calc doc.platform.nodes.omp_threads_for(chgres_resources[0])
  CHGRP_CMD: "'chgrp rstprod'"
  DONST: NO
  KEEPDATA: NO
  QUILTING: YES
  OUTPUT_GRID: "gaussian_grid"
  SMOOTH_ENKF: YES
  VERBOSE: YES
  WRITE_NEMSIOFILE: YES
  assim_freq: 6
  J_JOB: ecen

anal: &anal_action !Action
  <<: *action_template
  J_JOB: anal
  walltime: !timedelta 02:00:00
  resources: !calc run_anal.resources
  resources: !calc run_test.resources
  anal_resources: !calc run_anal.resources
  gsi_resources: !calc run_gsi.resources
  memory: "3072M"
  accounting: !calc doc.platform.parallel_accounting
  assim_freq: 6
  APRUN_CALCINC: "'mpirun -np $ncmd'"
  APRUN_GSI: "'mpirun -np 144'"
  ANALYSISSH: !expand "{BASE_GSI}/scripts/exglobal_analysis_fv3gfs.sh.ecf"
  ATARDIR: "/NCEPDEV/emc-global/1year/Samuel.Trahan/THEIA/scratch/wham"
  BASE_ENV: !expand "{doc.case.HOMEgfs}/gfs_workflow.v15.0.0/env"
  BASE_JOB: !expand "{doc.case.BASE_WORKFLOW}/jobs"
  CHGRP_CMD: "'chgrp rstprod'"
  DONST: NO
  ANALYSISSH: !expand "{doc.case.BASE_GSI}/scripts/exglobal_analysis_fv3gfs.sh.ecf"
  GSIEXEC: !expand "{doc.case.BASE_GSI}/exec/global_gsi"
  npe_anal: !calc resources.total_ranks()
  npe_gsi: !calc npe_anal
  nth_gsi: !calc doc.platform.nodes.omp_threads_for(gsi_resources[0])
  NTHREADS_GSI: !calc nth_gsi
  nth_anal: !calc doc.platform.nodes.omp_threads_for(anal_resources[0])
  KEEPDATA: NO
  NTHREADS_CALCINC: 1
  NTHSTACK: 1024000000
  OUTPUT_GRID: "gaussian_grid"
  QUILTING: YES
  SMOOTH_ENKF: YES
  VERBOSE: YES
  WRITE_NEMSIOFILE: YES

epos: &epos_action !Action
  <<: *action_template
  APRUN_EPOS: "'mpirun -np 84'"
  CASE: !calc doc.case.CASE_ENKF
  J_JOB: epos
  walltime: !timedelta 00:15:00
  resources: !calc run_epos.resources
  memory: "3072M"
  ATARDIR: "/NCEPDEV/emc-global/1year/Samuel.Trahan/THEIA/scratch/wham"
  BASE_ENV: !expand "{doc.case.HOMEgfs}/gfs_workflow.v15.0.0/env"
  BASE_JOB: !expand "{doc.case.BASE_WORKFLOW}/jobs"
  CHGRP_CMD: "'chgrp rstprod'"
  DONST: NO
  ENKFPOSTSH: !expand "{doc.case.BASE_GSI}/scripts/EnKF/scripts_ncep/exglobal_enkf_post_fv3gfs.sh.ecf"
  KEEPDATA: NO
  nth_epos: !calc doc.platform.nodes.omp_threads_for(resources[0])
  OUTPUT_GRID: "gaussian_grid"
  QUILTING: YES
  SMOOTH_ENKF: YES
  VERBOSE: YES
  WRITE_NEMSIOFILE: YES
  accounting: !calc doc.platform.parallel_accounting

eobs: &eobs_action !Action
  <<: *anal_action
  J_JOB: eobs
  CASE: !calc doc.case.CASE_ENKF
  walltime: !timedelta 00:15:00
  resources: !calc run_eobs.resources
  gsi_resources: !calc run_gsi.resources
  memory: "3072M"
  INVOBSSH: !expand "{doc.case.BASE_GSI}/scripts/exglobal_innovate_obs_fv3gfs.sh.ecf"
  ENKFINVOBSSH: !expand "{doc.case.BASE_GSI}/scripts/EnKF/scripts_ncep/exglobal_enkf_innovate_obs_fv3gfs.sh.ecf"
  NMEM_EOMGGRP: 10
  RERUN_EOMGGRP: "YES"
  npe_eobs: !calc resources.total_ranks()
  npe_gsi: !calc npe_eobs
  nth_gsi: !calc doc.platform.nodes.omp_threads_for(gsi_resources[0])
# GSI namelist options related to observer for EnKF
  OBSINPUT_INVOBS: "dmesh(1)=225.0,dmesh(2)=225.0"
  OBSQC_INVOBS: "tcp_width=60.0,tcp_ermin=2.0,tcp_ermax=12.0"
  nth_eobs: !calc doc.platform.nodes.omp_threads_for(resources[0])

eomg: &eomg_action !Action
  <<: *action_template
  J_JOB: eomg
  CASE: !calc doc.case.CASE_ENKF
  walltime: !timedelta 00:15:00
  resources: !calc run_eomg.resources
  memory: "3072M"
  nth_eomg: !calc doc.platform.nodes.omp_threads_for(resources[0])

eupd: &eupd_action !Action
  <<: *action_template
  J_JOB: eupd
  CASE: !calc doc.case.CASE_ENKF
  walltime: !timedelta 00:15:00
  resources: !calc run_eupd.resources
  enkf_resources: !calc run_enkf.resources
  eupd_resources: !calc run_eupd.resources
  memory: "3072M"
  ENKFUPDSH: !expand "{doc.case.BASE_GSI}/scripts/EnKF/scripts_ncep/exglobal_enkf_update_fv3gfs.sh.ecf"
  ENKFEXEC: !expand "{doc.case.BASE_GSI}/exec/global_enkf"
  npe_eupd: !calc resources.total_ranks()
  npe_enkf: !calc npe_eupd
  nth_enkf: !calc doc.platform.nodes.omp_threads_for(enkf_resources[0])
  nth_eupd: !calc doc.platform.nodes.omp_threads_for(eupd_resources[0])

efcs: &efcs_action !Action
  <<: *action_template
  J_JOB: efcs
  CASE: !calc doc.case.CASE_ENKF
  walltime: !timedelta 00:15:00
  efcs_resources: !JobRequest
    - exe: placeholder
      mpi_ranks: !calc "layout_x*layout_y*6"
      OMP_NUM_THREADS: 1
  resources: !calc efcs_resources
  memory: "3072M"
  npe_efcs: !calc efcs_resources.total_ranks()
  npe_fv3: !calc efcs_resources.total_ranks()
  nth_fv3: !calc doc.platform.nodes.omp_threads_for(resources[0])

  ENKFFCSTSH: !expand "{doc.case.BASE_GSI}/scripts/EnKF/scripts_ncep/exglobal_enkf_fcst_fv3gfs.sh.ecf"
  NMEM_EFCSGRP: 10
  RERUN_EFCSGRP: "NO"

# Stochastic physics parameters (only for ensemble forecasts)
  SET_STP_SEED: "YES"
  DO_SKEB: ".false."
  SKEB: 0.8
  SKEB_TAU: 21600.
  SKEB_LSCALE: 500000.
  SKEBNORM: 1
  DO_SHUM: ".false."
  SHUM: 0.006
  SHUM_TAU: 21600.
  SHUM_LSCALE: 250000.
  DO_SPPT: ".false."
  SPPT: 0.8
  SPPT_TAU: 21600.
  SPPT_LSCALE: 500000.

  DIAG_TABLE: !expand "{doc.case.BASE_GSM}/parm/parm_fv3diag/diag_table_da"
  restart_interval: 6

  nth_efcs: !calc doc.platform.nodes.omp_threads_for(resources[0])

earc: &earc_action !Action
  <<: *action_template
  CASE: !calc doc.case.CASE_ENKF
  J_JOB: earc
  walltime: !timedelta 00:15:00
  resources: !calc run_earc.resources
  memory: "3072M"
  NMEM_EARCGRP: 10
  nth_earc: !calc doc.platform.nodes.omp_threads_for(resources[0])
  accounting: !calc doc.platform.transfer_accounting

final: &final_action !Action
  <<: *action_template
  walltime: !timedelta 00:03:00
  resources: !calc run_nothing.resources
  memory: "100M"
  accounting: !calc doc.platform.serial_accounting
  J_JOB: /bin/true

prep: &prep_action !Action
  <<: *action_template
  J_JOB: prep
  walltime: !timedelta 00:10:00
  resources: !calc run_prep.resources
  memory: "3072M"
  DO_RELOCATE: "NO"
  DO_MAKEPREPBUFR: "YES"   # if NO, will copy prepbufr from globaldump
  DRIVE_MAKEPREPBUFRSH: !expand "{doc.case.BASE_GSM}/ush/drive_makeprepbufr.sh"
  nth_prep: !calc doc.platform.nodes.omp_threads_for(resources[0])

fcst: &fcst_action !Action
  <<: *action_template
  J_JOB: fcst
  #npe_fcst: !calc "layout_x*layout_y*6"
  fcst_resources: !JobRequest
    - exe: placeholder
      mpi_ranks: !calc "layout_x*layout_y*6"
      OMP_NUM_THREADS: 2
  npe_fcst: !calc fcst_resources.total_ranks()
  walltime: !timedelta 00:10:00
  resources: !calc fcst_resources
  memory: "3072M"
  FORECASTSH: !expand "{doc.case.BASE_GSM}/scripts/exglobal_fcst_nemsfv3gfs.sh"
  FCSTEXECDIR: !expand "{doc.case.BASE_NEMSfv3gfs}/NEMS/exe"
  FCSTEXEC: "fv3_gfs_nh.prod.32bit.x"
  npe_fv3: !calc npe_fcst # This is model resolution dependent, see note above
  nth_fv3: !calc doc.platform.nodes.omp_threads_for(resources[0])
  TYPE: "nh"
  MONO: "non-mono"
  do_vort_damp: ".true."    # vorticity and divergence damping
  consv_te: "0."            # conserve total energy
  fv_sg_adj: 900            # time-scale to remove 2dz instability
  dspheat: ".false."        # dissipative heating
  shal_cnv: ".true."        # shallow convection
  agrid_vel_rst: ".true."   # write velocity restarts on agrid?

# Disable the use of coupler.res; get model start time from model_configure
# export USE_COUPLER_RES="NO"

  USE_COUPLER_RES: "NO"

  restart_interval: !FirstTrue
    - when: !calc CDUMP=="gdas"
      do: 6
    - otherwise: 0

  DIAG_TABLE: !FirstTrue
    - when: !calc CDUMP=="gdas"
      do: !expand "{doc.case.BASE_GSM}/parm/parm_fv3diag/diag_table_da"
    - when: !calc CDUMP=="gfs"
      do: !expand "{doc.case.BASE_GSM}/parm/parm_fv3diag/diag_table"
    - otherwise: !error "Do not know DIAG_TABLE for CDUMP={CDUMP}"

  REGRID_NEMSIO_SH: !expand "{doc.case.BASE_GSM}/ush/fv3gfs_regrid_nemsio.sh"
  REGRID_NEMSIO_TBL: !expand "{doc.case.BASE_GSM}/parm/parm_fv3diag/variable_table_da.txt"

  REMAPSH: !expand "{doc.case.BASE_GSM}/ush/fv3gfs_remap.sh"
  master_grid: "0p5deg" # 1deg 0p5deg 0p25deg 0p125deg etc
  npe_remap: !calc npe_fcst
  nth_remap: 2
  NC2NEMSIOSH: !expand "{doc.case.BASE_GSM}/ush/fv3gfs_nc2nemsio.sh"
  nth_fcst: 2

post: &post_action !Action
  <<: *action_template
  J_JOB: post
  walltime: !timedelta 00:15:00
  resources: !calc run_post.resources
  memory: "3072M"
  POSTJJOBSH: !expand "{doc.case.BASE_WORKFLOW}/jobs/JGFS_POST.sh"
  POSTGPSH: !expand "{doc.case.BASE_POST}/ush/global_nceppost.sh"
  POSTGPEXEC: !expand "{doc.case.BASE_POST}/exec/ncep_post"
  npe_post: !calc resources.total_ranks()
  npe_postgp: !calc npe_post
  nth_postgp: 1
  GFS_DOWNSTREAM: "YES"
  GFSDOWNSH: !expand "{doc.case.BASE_WORKFLOW}/ush/fv3gfs_downstream_nems.sh"
  GFSDWNSH: !expand "{doc.case.BASE_WORKFLOW}/ush/fv3gfs_dwn_nems.sh"
  downset: 1
  npe_dwn: !calc npe_post
  nth_dwn: !calc doc.platform.nodes.omp_threads_for(resources[0])
  nth_post: !calc doc.platform.nodes.omp_threads_for(resources[0])

arch: &arch_action !Action
  <<: *action_template
  J_JOB: arch
  walltime: !timedelta 06:00:00
  resources: !calc run_arch.resources
  memory: "3072M"
  nth_arch: !calc doc.platform.nodes.omp_threads_for(resources[0])
  accounting: !calc doc.platform.transfer_accounting

vrfy: &vrfy_action !Action
  <<: [ *case, *action_template ]
  J_JOB: vrfy
  Template:
    <<: [ *vrfy_template, *fv3_resolution ]
  walltime: !timedelta 01:00:00
  resources: !calc run_vrfy.resources
  memory: "3072M"
  accounting: !calc doc.platform.parallel_accounting
#  CDUMP: "gfs"
  VDUMP: "gfs"       # verifying dump
  CDUMPFCST: "gdas"  # Fit-to-obs with GDAS/GFS prepbufr
  CDFNL: "gdas"      # Scores verification against GDAS/GFS analysis
  VSDB_STEP1: "YES"      # populate VSDB database
  VSDB_STEP2: "NO"
  VRFYG2OBS: "YES"       # Grid to observations
  VRFYFITS: "YES"        # Fit to observations
  VRFYPRCP: "YES"        # Precip threat scores
  VRFYMINMON: "YES"      # GSI minimization monitoring
  VRFYRAD: "YES"         # Radiance data assimilation monitoring
  VRFYOZN: "NO"          # Ozone data assimilation monitoring
  VRFYTRAK: "YES"        # Hurricane track forecasts
  VRFYGENESIS: "YES"     # Cyclone genesis
  VRFYGMPK: "NO"         # Gempak verification
  nth_vrfy: !calc doc.platform.nodes.omp_threads_for(resources[0])
