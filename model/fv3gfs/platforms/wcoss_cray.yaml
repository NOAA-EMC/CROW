
wcoss_cray: &wcoss_cray !Platform
  <<: *resource_defaults
  name: WCOSS_C
  Evaluate: false
  detect: !calc |
    tools.isdir("/gpfs/hps") and \
    tools.isfile("/etc/SuSE-release")
  default_cpu_project: GFS-T2O
  serial_accounting:
    queue: dev
    project: !calc doc.accounting.cpu_project
  transfer_accounting:
    queue: transfer
    project: !calc doc.accounting.cpu_project
  parallel_accounting:
    queue: dev
    project: !calc doc.accounting.cpu_project

  scheduler_settings: &wcoss_cray_scheduler
    name: LSFAlps
    physical_cores_per_node: 24
    logical_cpus_per_core: 2
    hyperthreading_allowed: true
    indent_text: "  "
  parallelism_settings: { <<: *wcoss_cray_scheduler, name: LSFAlps }
  node_type_settings:   { <<: *wcoss_cray_scheduler, node_type: generic }

  mpi_tuning: 
      # FIXME: Update for WCOSS Cray
      MPI_BUFS_PER_HOST: 2048
      MPI_BUFS_PER_PROC: 2048
      MPI_GROUP_MAX: 256
      MPI_MEMMAP_OFF: 1
      MP_STDOUTMODE: "ORDERED"
      NTHSTACK: 1024000000
      OMP_STACKSIZE: 2048000

  scheduler: !calc |
    tools.get_scheduler(scheduler_settings.name, scheduler_settings)
  parallelism: !calc |
    tools.get_parallelism(parallelism_settings.name, parallelism_settings)
  nodes: !calc |
    tools.node_tool_for(node_type_settings.node_type, node_type_settings)

  BASE_SVN:  "/gpfs/hps3/emc/global/noscrub/emc.glopara/svn"

  general_env:
    POSTGRB2TBL: "/gpfs/hps/nco/ops/nwprod/lib/g2tmpl/v1.3.0/src/params_grib2_tbl_new"
    CHGRP_CMD: chgrp rstprod

  # Path to mmlsquota, the program used to get GPFS disk usage information:
  mmlsquota: "/usr/lpp/mmfs/bin/mmlsquota"
  least_used_scrub: !Immediate
    - !FirstMax
      - do: /gpfs/hps2/ptmp
        when: !calc tools.gpfs_gb(do,"hps2-ptmp","hps2",mmlsquota)
      - do: /gpfs/hps3/ptmp
        when: !calc tools.gpfs_gb(do,"hps3-ptmp","hps3",mmlsquota)
